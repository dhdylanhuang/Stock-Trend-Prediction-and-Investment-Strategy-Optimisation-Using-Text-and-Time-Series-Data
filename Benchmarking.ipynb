{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Results from Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgZ_ylAADNb6",
    "outputId": "6134cc02-4bf2-4dbb-a201-b8fd4d0df03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_ta_classic in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (0.3.36)\n",
      "Requirement already satisfied: numpy>=2.0.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.1.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2021.1 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2025.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (1.16.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas>=2.0.0->pandas_ta_classic) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas_ta_classic in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (0.3.36)\n",
      "Requirement already satisfied: numpy>=2.0.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.1.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2021.1 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (2025.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas_ta_classic) (1.16.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from pandas>=2.0.0->pandas_ta_classic) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (21.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas_ta_classic\n",
    "%pip install --upgrade pandas_ta_classic\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "befeuglqHy8f",
    "outputId": "a2bcece3-930c-4c77-c6ff-3473d1fde791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the problematic import line in squeeze_pro.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import site\n",
    "import os\n",
    "\n",
    "# Find the path to the pandas_ta_classic library and patch it\n",
    "pandas_ta_classic_path = None\n",
    "for sp in site.getsitepackages():\n",
    "    pandas_ta_classic_path = os.path.join(sp, 'pandas_ta_classic')\n",
    "    if os.path.exists(pandas_ta_classic_path):\n",
    "        break\n",
    "\n",
    "if pandas_ta_classic_path:\n",
    "    squeeze_pro_path = os.path.join(pandas_ta_classic_path, 'momentum', 'squeeze_pro.py')\n",
    "    if os.path.exists(squeeze_pro_path):\n",
    "        try:\n",
    "            with open(squeeze_pro_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            fixed = False\n",
    "            for line in lines:\n",
    "                if \"from numpy import NaN as npNaN\" in line:\n",
    "                    new_lines.append(line.replace(\"from numpy import NaN as npNaN\", \"# from numpy import NaN as npNaN\\nimport numpy as np\\n\"))\n",
    "                    fixed = True\n",
    "                    print(\"Modified import statement in squeeze_pro.py\")\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "\n",
    "            if fixed:\n",
    "                with open(squeeze_pro_path, 'w') as f:\n",
    "                    f.writelines(new_lines)\n",
    "                print(\"Successfully patched pandas_ta_classic/momentum/squeeze_pro.py\")\n",
    "            else:\n",
    "                print(\"Could not find the problematic import line in squeeze_pro.py\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error modifying squeeze_pro.py: {e}\")\n",
    "    else:\n",
    "        print(f\"Could not find squeeze_pro.py at {squeeze_pro_path}\")\n",
    "else:\n",
    "    print(\"Could not find the pandas_ta_classic library installation path.\")\n",
    "\n",
    "import pandas_ta_classic as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.8.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dylanhuang/micromamba/envs/df_ae2/lib/python3.13/site-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install scikit-learn\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "    mean_squared_error, mean_absolute_error, r2_score, confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import scipy\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unicodedata import bidirectional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion(y_true, y_pred, labels=None, normalize=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels, normalize=normalize)\n",
    "    return cm\n",
    "\n",
    "def plot_confusion(cm, labels, title=\"Confusion Matrix\"):\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(ax=ax, values_format=\".2f\" if cm.dtype.kind=='f' else \"d\", cmap='Blues', colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def aggregate_confusions(results_df, problem_type):\n",
    "    matrices = results_df['confusion_matrix'].dropna().apply(np.array)\n",
    "    if matrices.empty: \n",
    "        return None\n",
    "    agg = np.sum(np.stack(matrices.values, axis=0), axis=0)\n",
    "    labels = [0,1] if problem_type == 'classification' else [0,1,2,3,4,5]\n",
    "    return agg, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # Optional: stricter determinism (may slow down training)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_global_seeds(42)\n",
    "\n",
    "# Datasets\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Models\n",
    "class RNNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared head:\n",
    "      - RNN stack (LSTM/GRU, uni/bi)\n",
    "      - BatchNorm + Dense(32, ReLU) + Dropout(0.3)\n",
    "      - Output layer (1 unit): linear (regression) or logits (classification)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, rnn_type='LSTM', bidirectional=False, problem_type='regression', output_dim=1):\n",
    "        super().__init__()\n",
    "        hidden1 = 128\n",
    "        hidden2 = 64\n",
    "        self.problem_type = problem_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn_type = rnn_type.upper()\n",
    "\n",
    "        rnn_cls = {'LSTM': nn.LSTM, 'GRU': nn.GRU}[('GRU' if 'GRU' in self.rnn_type else 'LSTM')]\n",
    "\n",
    "        self.rnn1 = rnn_cls(\n",
    "            input_size=input_size, hidden_size=hidden1, num_layers=1,\n",
    "            batch_first=True, dropout=0.0, bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        self.inter_rnn_drop = nn.Dropout(0.1)\n",
    "        \n",
    "        self.rnn2 = rnn_cls(\n",
    "            input_size=hidden1*(2 if bidirectional else 1), hidden_size=hidden2, num_layers=1,\n",
    "            batch_first=True, dropout=0.0, bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        feat_dim = hidden2*(2 if bidirectional else 1)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(feat_dim)\n",
    "        self.fc = nn.Linear(feat_dim, 32)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(32, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        out, _ = self.rnn1(x)\n",
    "        out = self.inter_rnn_drop(out)   # inter-layer dropout (sequence-wise)\n",
    "        out, _ = self.rnn2(out)\n",
    "        # take last timestep: [B, T, H] -> [B, H]\n",
    "        out = out[:, -1, :]\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(self.fc(out))\n",
    "        out = self.drop(out)\n",
    "        out = self.out(out)  # shape [B, 1] or [B, output_dim]\n",
    "        return out  # regression: raw; classification: logits\n",
    "\n",
    "def build_model(input_shape, model_type='LSTM', problem_type='regression'):\n",
    "    seq_len, n_features = input_shape\n",
    "    output_dim = 6 if problem_type == 'multiclass' else 1\n",
    "    model_type = model_type.upper()\n",
    "    if model_type == 'LSTM':\n",
    "        return RNNHead(n_features, rnn_type='LSTM', bidirectional=False, problem_type=problem_type, output_dim=output_dim)\n",
    "    elif model_type == 'BILSTM':\n",
    "        return RNNHead(n_features, rnn_type='LSTM', bidirectional=True, problem_type=problem_type, output_dim=output_dim)\n",
    "    elif model_type == 'GRU':\n",
    "        return RNNHead(n_features, rnn_type='GRU', bidirectional=False, problem_type=problem_type, output_dim=output_dim)\n",
    "    elif model_type == 'BIGRU':\n",
    "        return RNNHead(n_features, rnn_type='GRU', bidirectional=True, problem_type=problem_type, output_dim=output_dim)\n",
    "    else:\n",
    "        raise ValueError(\"Model type must be one of: ['LSTM','BiLSTM','GRU','BiGRU']\")\n",
    "\n",
    "# Early Stopping (PyTorch)\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=15, min_delta=0.0, restore_best=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best = restore_best\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, val_loss, model):\n",
    "        improved = (self.best_loss - val_loss) > self.min_delta\n",
    "        if improved:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.restore_best:\n",
    "                # Deep copy state dict\n",
    "                self.best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        if self.restore_best and self.best_state is not None:\n",
    "            model.load_state_dict(self.best_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_BINS   = [-float('inf'), -0.15, -0.08, 0.0, 0.08, 0.15, float('inf')]\n",
    "BUCKET_LABELS = [0, 1, 2, 3, 4, 5]   \n",
    "BUCKET_LABEL_NAMES = {\n",
    "    0: \"≤ -15%\",\n",
    "    1: \"(-15,-8]%\",\n",
    "    2: \"(-8,0]%\",\n",
    "    3: \"(0,8]%\",\n",
    "    4: \"(8,15]%\",\n",
    "    5: \"≥ 15%\"\n",
    "}\n",
    "\n",
    "display_labels = [BUCKET_LABEL_NAMES[i] for i in BUCKET_LABELS]\n",
    "\n",
    "def pct_return(series, h):\n",
    "    return series.shift(-h) / series - 1.0\n",
    "\n",
    "def bucketise_returns(ret_series):\n",
    "    return pd.cut(ret_series, bins=BUCKET_BINS, labels=BUCKET_LABELS, include_lowest=True, right=True).astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fGvgtiPTiBQ4"
   },
   "outputs": [],
   "source": [
    "class StockPredictionPipeline:\n",
    "    def __init__(self, df, feature_columns, model_type='LSTM', sequence_length=30, problem_type='regression', horizon_steps=1):\n",
    "        self.df = df.copy()\n",
    "        self.feature_columns = feature_columns\n",
    "        self.model_type = model_type\n",
    "        self.sequence_length = sequence_length\n",
    "        self.problem_type = problem_type\n",
    "        self.horizon_steps = horizon_steps\n",
    "        self.results = []\n",
    "        self.loss_curves = []\n",
    "\n",
    "        # Validate\n",
    "        self._validate_inputs()\n",
    "\n",
    "        # Device & precision\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.mixed_precision = torch.cuda.is_available()\n",
    "\n",
    "        print(f\"Pipeline initialized for a '{self.problem_type}' problem \"\n",
    "              f\"with horizon {self.horizon_steps} steps. Device: {self.device}\")\n",
    "\n",
    "    def _validate_inputs(self):\n",
    "        missing_cols = [col for col in self.feature_columns if col not in self.df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing feature columns: {missing_cols}\")\n",
    "\n",
    "        if 'close' not in self.df.columns and 'close_price' not in self.df.columns:\n",
    "            raise ValueError(\"No 'close' or 'close_price' column found in data\")\n",
    "\n",
    "        valid_models = ['LSTM', 'BiLSTM', 'GRU', 'BiGRU']\n",
    "        if self.model_type not in valid_models:\n",
    "            raise ValueError(f\"Model type must be one of: {valid_models}\")\n",
    "\n",
    "        if self.problem_type not in ['regression', 'classification', 'multiclass']:\n",
    "            raise ValueError(\"Problem type must be 'regression', 'classification', or 'multiclass'\")\n",
    "\n",
    "    def create_target_variable(self, company_data):\n",
    "        company_data = company_data.copy()\n",
    "        price_col = 'close' if 'close' in company_data.columns else 'close_price'\n",
    "        if 'date' in company_data.columns:\n",
    "            company_data = company_data.sort_values('date')\n",
    "            \n",
    "        h = self.horizon_steps\n",
    "\n",
    "        company_data['target_regression'] = (\n",
    "            np.log(company_data[price_col].shift(-h)) - np.log(company_data[price_col])\n",
    "        )\n",
    "        company_data['target_direction'] = (company_data['target_regression'] > 0).astype(int)\n",
    "        \n",
    "        company_data['ret_h'] = pct_return(company_data[price_col], h)\n",
    "        company_data['y_bucket'] = bucketise_returns(company_data['ret_h'])\n",
    "        \n",
    "        company_data = company_data.dropna(subset=['target_regression', 'ret_h', 'y_bucket'])\n",
    "        return company_data\n",
    "\n",
    "    def create_sequences(self, features, *targets):\n",
    "        X = []\n",
    "        y_sequences = [[] for _ in targets]\n",
    "        for i in range(self.sequence_length, len(features)):\n",
    "            X.append(features[i-self.sequence_length:i])\n",
    "            for j, target in enumerate(targets):\n",
    "                y_sequences[j].append(target[i])\n",
    "        return (np.array(X),) + tuple(np.array(y) for y in y_sequences)\n",
    "\n",
    "    def _train_one_epoch(self, model, loader, optimizer, loss_fn, scaler):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(self.device)\n",
    "            yb = yb.to(self.device)\n",
    "            if self.problem_type in ['regression', 'classification']:\n",
    "                yb = yb.view(-1, 1) #single output heads\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            ctx = torch.amp.autocast('cuda') if self.mixed_precision else nullcontext()\n",
    "            with ctx:\n",
    "                logits = model(xb)\n",
    "                if self.problem_type == 'multiclass':\n",
    "                    loss = loss_fn(logits, yb.long())\n",
    "                else:\n",
    "                    loss = loss_fn(logits, yb)\n",
    "\n",
    "            if self.mixed_precision:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        return total_loss / len(loader.dataset)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _eval_one_epoch(self, model, loader, loss_fn):\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(self.device)\n",
    "            yb = yb.to(self.device)\n",
    "            \n",
    "            if self.problem_type in ['regression', 'classification']:\n",
    "                yb = yb.view(-1, 1) #single output heads\n",
    "                \n",
    "            logits = model(xb)\n",
    "            if self.problem_type == 'multiclass':\n",
    "                loss = loss_fn(logits, yb.long())\n",
    "            else:\n",
    "                loss = loss_fn(logits, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "        return total_loss / len(loader.dataset)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _predict(self, model, loader):\n",
    "        model.eval()\n",
    "        outs = []\n",
    "        for xb, _ in loader:\n",
    "            xb = xb.to(self.device)\n",
    "            logits = model(xb).squeeze(1).detach().cpu().numpy()\n",
    "            outs.append(logits)\n",
    "        return np.concatenate(outs, axis=0)\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        model = build_model(input_shape, model_type=self.model_type, problem_type=self.problem_type)\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def process_company(self, company_name, company_data, sector):\n",
    "        print(f\"\\nProcessing {company_name} ({sector})...\")\n",
    "        try:\n",
    "            company_data = self.create_target_variable(company_data)\n",
    "\n",
    "            # Min samples requirement (same heuristic)\n",
    "            min_samples = self.sequence_length + 150 + self.horizon_steps\n",
    "            if len(company_data) < min_samples:\n",
    "                print(f\"Insufficient data for {company_name} ({len(company_data)} < {min_samples}). Skipping...\")\n",
    "                return None\n",
    "\n",
    "            if company_data[self.feature_columns].isnull().any().any():\n",
    "                print(f\"Missing values in features for {company_name}. Skipping...\")\n",
    "                return None\n",
    "\n",
    "            features = company_data[self.feature_columns].values\n",
    "            target_reg = company_data['target_regression'].values\n",
    "            target_dir = company_data['target_direction'].values\n",
    "            target_bucket = company_data['y_bucket'].values.astype(int)\n",
    "\n",
    "            # Create sequences\n",
    "            X_raw, y_reg, y_dir, y_bucket = self.create_sequences(features, target_reg, target_dir, target_bucket)\n",
    "\n",
    "            # TimeSeriesSplit\n",
    "            n_splits = min(5, len(X_raw) // 50)\n",
    "            if n_splits < 3:\n",
    "                print(f\"Insufficient data for proper time series validation for {company_name}. Skipping...\")\n",
    "                return None\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "            splits = list(tscv.split(X_raw))\n",
    "            train_idx, test_idx = splits[-1]\n",
    "\n",
    "            # Train/Val split (last 20% of train for val)\n",
    "            val_size = int(0.2 * len(train_idx))\n",
    "            final_train_idx = train_idx[:-val_size]\n",
    "            val_idx = train_idx[-val_size:]\n",
    "            \n",
    "            if self.horizon_steps > 1:\n",
    "                print(\"Adjusting for multi-step horizon...\")\n",
    "                gap = self.horizon_steps\n",
    "                if len(final_train_idx) > gap:\n",
    "                    final_train_idx = final_train_idx[:-gap]  # drop last h labels from train\n",
    "                if len(val_idx) > gap:\n",
    "                    val_idx = val_idx[gap:]  # drop last h labels from val\n",
    "\n",
    "            X_train_raw, X_val_raw, X_test_raw = X_raw[final_train_idx], X_raw[val_idx], X_raw[test_idx]\n",
    "            \n",
    "            F = X_raw.shape[-1]\n",
    "            feat_scaler = StandardScaler()\n",
    "            X_train = feat_scaler.fit_transform(X_train_raw.reshape(-1, F)).reshape(X_train_raw.shape)\n",
    "            X_val   = feat_scaler.transform(X_val_raw.reshape(-1, F)).reshape(X_val_raw.shape)\n",
    "            X_test  = feat_scaler.transform(X_test_raw.reshape(-1, F)).reshape(X_test_raw.shape)\n",
    "\n",
    "            if self.problem_type == 'regression':\n",
    "                y_train, y_val, y_test = y_reg[final_train_idx], y_reg[val_idx], y_reg[test_idx]\n",
    "                target_scaler = StandardScaler()\n",
    "                y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "                y_val_scaled   = target_scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
    "                train_target, val_target = y_train_scaled, y_val_scaled\n",
    "\n",
    "            # Class balance note\n",
    "            elif self.problem_type == 'classification':\n",
    "                y_train, y_val, y_test = y_dir[final_train_idx], y_dir[val_idx], y_dir[test_idx]\n",
    "                train_target, val_target = y_train, y_val\n",
    "                target_scaler = None\n",
    "                class_ratio = np.mean(y_train)\n",
    "                if class_ratio < 0.1 or class_ratio > 0.9:\n",
    "                    print(f\"Severe class imbalance for {company_name} ({class_ratio:.3f}). Consider using class weights.\")\n",
    "\n",
    "            elif self.problem_type == 'multiclass':\n",
    "                y_train, y_val, y_test = y_bucket[final_train_idx], y_bucket[val_idx], y_bucket[test_idx]\n",
    "                train_target, val_target = y_train, y_val\n",
    "                target_scaler = None\n",
    "            else:\n",
    "                raise ValueError(\"Unknown problem type.\")\n",
    "            \n",
    "\n",
    "            # Datasets & loaders\n",
    "            if self.problem_type == 'multiclass':\n",
    "                train_ds = SequenceDataset(X_train, train_target.astype(np.int64))\n",
    "                val_ds   = SequenceDataset(X_val,   val_target.astype(np.int64))\n",
    "                test_ds  = SequenceDataset(X_test,  y_test.astype(np.int64))\n",
    "            else:\n",
    "                train_ds = SequenceDataset(X_train, train_target)\n",
    "                val_ds   = SequenceDataset(X_val,   val_target)\n",
    "                test_ds  = SequenceDataset(X_test,  y_test)\n",
    "\n",
    "            train_loader = DataLoader(train_ds, batch_size=32, shuffle=False, drop_last=False, num_workers=0)\n",
    "            val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, drop_last=False, num_workers=0)\n",
    "            test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "            # Build model\n",
    "            model = self.build_model((self.sequence_length, len(self.feature_columns)))\n",
    "\n",
    "            # Loss functions\n",
    "            if self.problem_type == 'regression':\n",
    "                loss_fn = nn.HuberLoss(delta=1.0)\n",
    "            elif self.problem_type == 'classification':\n",
    "                # Use BCEWithLogitsLoss for numerical stability (logits input)\n",
    "                loss_fn = nn.BCEWithLogitsLoss()\n",
    "            elif self.problem_type == 'multiclass':\n",
    "                # class weights from TRAIN only (handle missing classes)\n",
    "                counts = np.bincount(train_target, minlength=6).astype(float)\n",
    "                weights = (counts.sum() / np.maximum(counts, 1.0))\n",
    "                weights = torch.tensor(weights, dtype=torch.float32, device=self.device)\n",
    "                loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "            # Optimizer & scheduler\n",
    "            optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-7, weight_decay=1e-5)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=7, min_lr=1e-7)\n",
    "            early_stopper = EarlyStopper(patience=15, min_delta=0.0, restore_best=True)\n",
    "            scaler = torch.amp.GradScaler('cuda', enabled=self.mixed_precision)\n",
    "\n",
    "            # Training loop\n",
    "            max_epochs = 100\n",
    "            best_val = float('inf')\n",
    "            epochs_trained = 0\n",
    "            company_loss_rows = []  \n",
    "\n",
    "            for epoch in range(1, max_epochs + 1):\n",
    "                train_loss = self._train_one_epoch(model, train_loader, optimizer, loss_fn, scaler)\n",
    "                val_loss = self._eval_one_epoch(model, val_loader, loss_fn)\n",
    "                scheduler.step(val_loss)\n",
    "                stop = early_stopper.step(val_loss, model)\n",
    "                epochs_trained = epoch\n",
    "                \n",
    "                row = {\n",
    "                    'company': company_name,\n",
    "                    'sector': sector,\n",
    "                    'model_type': self.model_type,\n",
    "                    'problem_type': self.problem_type,\n",
    "                    'sequence_length': self.sequence_length,\n",
    "                    'horizon_steps': self.horizon_steps,\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': float(train_loss),\n",
    "                    'val_loss': float(val_loss),\n",
    "                    'train_samples': len(X_train),\n",
    "                    'val_samples': len(X_val),\n",
    "                    'test_samples': len(X_test),\n",
    "                }\n",
    "                \n",
    "                company_loss_rows.append(row)\n",
    "                self.loss_curves.append(row)\n",
    "\n",
    "                if epoch % 10 == 0 or stop:\n",
    "                    print(f\"  Epoch {epoch:03d} - train {train_loss:.5f} | val {val_loss:.5f}\")\n",
    "\n",
    "                if stop:\n",
    "                    break\n",
    "\n",
    "            # Restore best model weights (like Keras restore_best_weights=True)\n",
    "            early_stopper.restore(model)\n",
    "\n",
    "            # Predictions\n",
    "            y_pred_raw = self._predict(model, test_loader)  # raw/regression or logits\n",
    "            \n",
    "            # Predictions\n",
    "            if self.problem_type == 'multiclass':\n",
    "                # Get logits on TEST\n",
    "                model.eval()\n",
    "                logits_list = []\n",
    "                with torch.no_grad():\n",
    "                    for xb, _ in test_loader:\n",
    "                        xb = xb.to(self.device)\n",
    "                        logits = model(xb)          # [B, 6]\n",
    "                        logits_list.append(logits.cpu())\n",
    "                logits = torch.cat(logits_list, dim=0)          # torch [N, 6]\n",
    "                probs  = torch.softmax(logits, dim=1).numpy()   # [N, 6] (no scipy needed)\n",
    "                y_pred_labels = probs.argmax(axis=1)\n",
    "                y_true_labels = y_test\n",
    "\n",
    "                # Confusion matrices (store AFTER building `result`)\n",
    "                labels = BUCKET_LABELS\n",
    "                cm_counts = compute_confusion(y_true_labels, y_pred_labels, labels=labels, normalize=None)\n",
    "                cm_norm   = compute_confusion(y_true_labels, y_pred_labels, labels=labels, normalize='true')\n",
    "\n",
    "                # Multiclass metrics\n",
    "                micro_acc = (y_true_labels == y_pred_labels).mean()\n",
    "                macro_f1  = f1_score(y_true_labels, y_pred_labels, average='macro', zero_division=0)\n",
    "\n",
    "                # Expected return from TRAIN bucket means\n",
    "                # Align returns with sequences: first sequence starts at index `sequence_length`\n",
    "                ret_seq_train = company_data['ret_h'].values[self.sequence_length:][final_train_idx]\n",
    "                bkt_seq_train = y_bucket[final_train_idx]  \n",
    "                mu_c = {c: (ret_seq_train[bkt_seq_train == c].mean() if np.any(bkt_seq_train == c) else 0.0)\n",
    "                        for c in range(6)}\n",
    "                expected_ret = (probs * np.array([mu_c[c] for c in range(6)])).sum(axis=1)\n",
    "                expected_ret_mean = float(expected_ret.mean())\n",
    "\n",
    "                # Optional: derive a binary \"direction\" from buckets to keep your binary metrics comparable\n",
    "                y_true_dir = (y_true_labels >= 3).astype(int)  # buckets 3,4,5 are \"up\"\n",
    "                y_pred_dir = (y_pred_labels >= 3).astype(int)\n",
    "                precision = precision_score(y_true_dir, y_pred_dir, zero_division=0)\n",
    "                recall    = recall_score(y_true_dir, y_pred_dir, zero_division=0)\n",
    "                f1        = f1_score(y_true_dir, y_pred_dir, zero_division=0)\n",
    "                mcc       = matthews_corrcoef(y_true_dir, y_pred_dir)\n",
    "                directional_accuracy = (y_true_dir == y_pred_dir).mean()\n",
    "                mse = mae = r2 = np.nan  # not applicable in multiclass\n",
    "\n",
    "                # Build result dict NOW, then attach matrices\n",
    "                result = {\n",
    "                    'company': company_name,\n",
    "                    'sector': sector,\n",
    "                    'model_type': self.model_type,\n",
    "                    'problem_type': self.problem_type,\n",
    "                    'horizon_steps': self.horizon_steps,\n",
    "                    'macro_f1': macro_f1,\n",
    "                    'micro_accuracy': micro_acc,\n",
    "                    'expected_return_mean': expected_ret_mean,\n",
    "                    'mse': mse,\n",
    "                    'mae': mae,\n",
    "                    'r2': r2,\n",
    "                    'mcc': mcc,\n",
    "                    'f1': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'directional_accuracy': directional_accuracy,\n",
    "                    'n_samples': int(X_raw.shape[0]),\n",
    "                    'train_samples': int(X_train.shape[0]),\n",
    "                    'val_samples': int(X_val.shape[0]),\n",
    "                    'test_samples': int(X_test.shape[0]),\n",
    "                    'epochs_trained': epochs_trained\n",
    "                }\n",
    "                result['confusion_matrix'] = cm_counts.tolist()\n",
    "                result['confusion_matrix_normalized'] = cm_norm.tolist()\n",
    "\n",
    "            elif self.problem_type == 'regression':\n",
    "                y_pred_raw = self._predict(model, test_loader)  # [N]\n",
    "                y_pred_unscaled = target_scaler.inverse_transform(y_pred_raw.reshape(-1,1)).flatten() if target_scaler is not None else y_pred_raw\n",
    "                mse = mean_squared_error(y_test, y_pred_unscaled)\n",
    "                mae = mean_absolute_error(y_test, y_pred_unscaled)\n",
    "                r2  = r2_score(y_test, y_pred_unscaled)\n",
    "\n",
    "                # Directional metrics (derived from sign)\n",
    "                y_test_dir = (y_reg[test_idx] > 0).astype(int)\n",
    "                y_pred_dir = (y_pred_unscaled > 0).astype(int)\n",
    "                precision = precision_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                recall    = recall_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                f1        = f1_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                mcc       = matthews_corrcoef(y_test_dir, y_pred_dir)\n",
    "                directional_accuracy = (y_test_dir == y_pred_dir).mean()\n",
    "\n",
    "                result = {\n",
    "                    'company': company_name,\n",
    "                    'sector': sector,\n",
    "                    'model_type': self.model_type,\n",
    "                    'problem_type': self.problem_type,\n",
    "                    'horizon_steps': self.horizon_steps,\n",
    "                    'macro_f1': np.nan,\n",
    "                    'micro_accuracy': np.nan,\n",
    "                    'expected_return_mean': np.nan,\n",
    "                    'mse': mse,\n",
    "                    'mae': mae,\n",
    "                    'r2': r2,\n",
    "                    'mcc': mcc,\n",
    "                    'f1': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'directional_accuracy': directional_accuracy,\n",
    "                    'n_samples': int(X_raw.shape[0]),\n",
    "                    'train_samples': int(X_train.shape[0]),\n",
    "                    'val_samples': int(X_val.shape[0]),\n",
    "                    'test_samples': int(X_test.shape[0]),\n",
    "                    'epochs_trained': epochs_trained\n",
    "                }\n",
    "\n",
    "            else:  # binary classification\n",
    "                y_pred_raw = self._predict(model, test_loader)  # logits [N]\n",
    "                probs = 1.0 / (1.0 + np.exp(-y_pred_raw))\n",
    "                y_pred_dir = (probs > 0.5).astype(int)\n",
    "                y_test_dir = y_test\n",
    "                mse = mae = r2 = np.nan\n",
    "\n",
    "                labels = [0, 1]\n",
    "                cm_counts = compute_confusion(y_test_dir, y_pred_dir, labels=labels, normalize=None)\n",
    "                cm_norm   = compute_confusion(y_test_dir, y_pred_dir, labels=labels, normalize='true')\n",
    "\n",
    "                precision = precision_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                recall    = recall_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                f1        = f1_score(y_test_dir, y_pred_dir, zero_division=0)\n",
    "                mcc       = matthews_corrcoef(y_test_dir, y_pred_dir)\n",
    "                directional_accuracy = (y_test_dir == y_pred_dir).mean()\n",
    "\n",
    "                result = {\n",
    "                    'company': company_name,\n",
    "                    'sector': sector,\n",
    "                    'model_type': self.model_type,\n",
    "                    'problem_type': self.problem_type,\n",
    "                    'horizon_steps': self.horizon_steps,\n",
    "                    'macro_f1': np.nan,\n",
    "                    'micro_accuracy': np.nan,\n",
    "                    'expected_return_mean': np.nan,\n",
    "                    'mse': mse,\n",
    "                    'mae': mae,\n",
    "                    'r2': r2,\n",
    "                    'mcc': mcc,\n",
    "                    'f1': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'directional_accuracy': directional_accuracy,\n",
    "                    'n_samples': int(X_raw.shape[0]),\n",
    "                    'train_samples': int(X_train.shape[0]),\n",
    "                    'val_samples': int(X_val.shape[0]),\n",
    "                    'test_samples': int(X_test.shape[0]),\n",
    "                    'epochs_trained': epochs_trained\n",
    "                }\n",
    "                result['confusion_matrix'] = cm_counts.tolist()\n",
    "                result['confusion_matrix_normalized'] = cm_norm.tolist()\n",
    "\n",
    "            # Logging\n",
    "            if self.problem_type == 'regression':\n",
    "                print(f\"  Regression -> MSE: {mse:.6f}, MAE: {mae:.6f}, R²: {r2:.4f}\")\n",
    "            elif self.problem_type == 'multiclass':\n",
    "                print(f\"  Multiclass -> Micro Acc: {micro_acc:.4f}, Macro F1: {macro_f1:.4f}, Expected Return: {expected_ret_mean:.6f}\")\n",
    "            else:\n",
    "                print(f\"  Directional -> Accuracy: {directional_accuracy:.4f}, MCC: {mcc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "            # Cleanup\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            return result\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {company_name}: {str(e)}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            return None\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        company_col = None\n",
    "        for col_name in ['ticker', 'company', 'symbol']:\n",
    "            if col_name in self.df.columns:\n",
    "                company_col = col_name\n",
    "                break\n",
    "        if company_col is None:\n",
    "            company_col = self.df.columns[0]\n",
    "            print(f\"Warning: Using '{company_col}' as company identifier column\")\n",
    "\n",
    "        companies = self.df[company_col].unique()\n",
    "        print(f\"Processing {len(companies)} companies with {self.model_type} model...\")\n",
    "        print(f\"Problem type: {self.problem_type}\")\n",
    "        print(f\"Sequence length: {self.sequence_length}\")\n",
    "        print(f\"Features: {self.feature_columns}\")\n",
    "\n",
    "        successful_companies = 0\n",
    "        for i, company in enumerate(companies, 1):\n",
    "            print(f\"\\n[{i}/{len(companies)}] Processing {company}...\")\n",
    "            company_data = self.df[self.df[company_col] == company].copy()\n",
    "            sector = company_data['sector'].iloc[0] if 'sector' in company_data.columns else 'Unknown'\n",
    "            result = self.process_company(company, company_data, sector)\n",
    "            if result:\n",
    "                self.results.append(result)\n",
    "                successful_companies += 1\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Pipeline completed: {successful_companies}/{len(companies)} companies processed successfully\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        if self.results:\n",
    "            self.results_df = pd.DataFrame(self.results)\n",
    "            return self.results_df\n",
    "        else:\n",
    "            print(\"No companies were processed successfully!\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def analyze_results(self):\n",
    "        if not hasattr(self, 'results_df') or self.results_df.empty:\n",
    "            print(\"No results to analyze!\")\n",
    "            return None\n",
    "\n",
    "        df = self.results_df\n",
    "        analysis = {}\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STOCK PREDICTION PIPELINE RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Model: {self.model_type} | Problem: {self.problem_type}\")\n",
    "        print(f\"Companies analyzed: {len(df)}\")\n",
    "        print(f\"Average samples per company: {df['n_samples'].mean():.0f}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"OVERALL PERFORMANCE\")\n",
    "        print(\"=\"*50)\n",
    "        if self.problem_type == 'regression':\n",
    "            print(f\"Mean Squared Error:     {df['mse'].mean():.6f} (±{df['mse'].std():.6f})\")\n",
    "            print(f\"Mean Absolute Error:    {df['mae'].mean():.6f} (±{df['mae'].std():.6f})\")\n",
    "            print(f\"R² Score:              {df['r2'].mean():.4f} (±{df['r2'].std():.4f})\")\n",
    "\n",
    "        elif self.problem_type == 'multiclass':\n",
    "            print(f\"Micro Accuracy:         {df['micro_accuracy'].mean():.4f} (±{df['micro_accuracy'].std():.4f})\")\n",
    "            print(f\"Macro F1 Score:         {df['macro_f1'].mean():.4f} (±{df['macro_f1'].std():.4f})\")\n",
    "            print(f\"Expected Return:        {df['expected_return_mean'].mean():.6f} (±{df['expected_return_mean'].std():.4f})\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"TOP 10 BY EXPECTED RETURN (mean)\")\n",
    "            print(\"=\"*50)\n",
    "            top_er = df.nlargest(10, 'expected_return_mean')\n",
    "            for _, row in top_er.iterrows():\n",
    "                print(f\"{row['company']:<20} | {row['sector']:<15} | \"\n",
    "                      f\"E[r]_mean: {row['expected_return_mean']:.4e} | Macro-F1: {row['macro_f1']:.3f}\")\n",
    "            \n",
    "        print(f\"Directional Accuracy:   {df['directional_accuracy'].mean():.4f} (±{df['directional_accuracy'].std():.4f})\")\n",
    "        print(f\"Matthews Correlation:   {df['mcc'].mean():.4f} (±{df['mcc'].std():.4f})\")\n",
    "        print(f\"F1 Score:              {df['f1'].mean():.4f} (±{df['f1'].std():.4f})\")\n",
    "        print(f\"Precision:             {df['precision'].mean():.4f} (±{df['precision'].std():.4f})\")\n",
    "        print(f\"Recall:                {df['recall'].mean():.4f} (±{df['recall'].std():.4f})\")\n",
    "\n",
    "        if 'sector' in df.columns and df['sector'].nunique() > 1:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"PERFORMANCE BY SECTOR\")\n",
    "            print(\"=\"*50)\n",
    "            sector_stats = df.groupby('sector').agg({\n",
    "                'directional_accuracy': ['mean', 'std', 'count'],\n",
    "                'mcc': ['mean', 'std'],\n",
    "                'r2': 'mean' if self.problem_type == 'regression' else lambda x: np.nan,\n",
    "                'mae': 'mean' if self.problem_type == 'regression' else lambda x: np.nan\n",
    "            }).round(4)\n",
    "            sector_stats.columns = ['_'.join(col).strip() if col[1] else col[0] for col in sector_stats.columns]\n",
    "            sector_stats = sector_stats.sort_values('directional_accuracy_mean', ascending=False)\n",
    "            for sector, row in sector_stats.iterrows():\n",
    "                print(f\"{sector:<20} | Acc: {row['directional_accuracy_mean']:.3f}±{row['directional_accuracy_std']:.3f} | \"\n",
    "                      f\"MCC: {row['mcc_mean']:.3f} | Companies: {int(row['directional_accuracy_count'])}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TOP 10 PERFORMERS (by Directional Accuracy)\")\n",
    "        print(\"=\"*50)\n",
    "        top_performers = df.nlargest(10, 'directional_accuracy')\n",
    "        for _, row in top_performers.iterrows():\n",
    "            print(f\"{row['company']:<20} | {row['sector']:<15} | \"\n",
    "                  f\"Acc: {row['directional_accuracy']:.3f} | MCC: {row['mcc']:.3f}\")\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def save_results(self, results, output_dir='results/benchmarking'):\n",
    "        if results is not None and not results.empty:\n",
    "            model_name = self.model_type\n",
    "\n",
    "            if self.problem_type == 'regression':\n",
    "                out_dir = os.path.join(output_dir, 'regression')\n",
    "            elif self.problem_type == 'classification':\n",
    "                out_dir = os.path.join(output_dir, 'classification')\n",
    "            else:\n",
    "                out_dir = os.path.join(output_dir, 'multiclass')\n",
    "\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            output_path = os.path.join(out_dir, f\"{model_name}.csv\")\n",
    "\n",
    "            results.to_csv(output_path, index=False)\n",
    "            print(f\"Results saved to {output_path}\")\n",
    "        else:\n",
    "            print(\"No results to save.\")\n",
    "            \n",
    "        \n",
    "            \n",
    "    def get_loss_curves_df(self):\n",
    "        if not self.loss_curves:\n",
    "            print(\"No loss curves logged yet.\")\n",
    "            return pd.DataFrame()\n",
    "        return pd.DataFrame(self.loss_curves)\n",
    "\n",
    "    def save_loss_curves(self, out_path='results/benchmarking/'):\n",
    "        df = self.get_loss_curves_df()\n",
    "        if df.empty:\n",
    "            print(\"No loss curves to save.\")\n",
    "            return\n",
    "        if self.problem_type == 'regression':\n",
    "            out_path = os.path.join(out_path, 'regression', f\"{self.model_type}_loss_curves.csv\")\n",
    "        else:\n",
    "            out_path = os.path.join(out_path, 'classification', f\"{self.model_type}_loss_curves.csv\")\n",
    "            \n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        \n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f\"Loss curves saved to {out_path}\")\n",
    "\n",
    "    def get_feature_importance_analysis(self):\n",
    "        print(\"Feature importance analysis not implemented yet.\")\n",
    "        print(\"Consider implementing SHAP values or permutation importance for better insights.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlCKxsDxHHFe",
    "outputId": "36aa45f2-ea60-4af0-f4ea-d3804481245f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/mdk91y8925ncdd32prjkcl_c0000gn/T/ipykernel_48995/1242874406.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df[col].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of master_df before dropping NaNs: (108592, 21)\n",
      "Shape of master_df after dropping NaNs: (108592, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/mdk91y8925ncdd32prjkcl_c0000gn/T/ipykernel_48995/1242874406.py:95: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  master_df = master_df.groupby('ticker').apply(apply_ta_indicators)\n"
     ]
    }
   ],
   "source": [
    "companies = pd.read_parquet('stocknet-dataset/stock_table.parquet')\n",
    "tweets = pd.read_parquet('stocknet-dataset/stock_tweets_withsentiment_withemotion_withstance_nomerge.parquet')\n",
    "stocks = pd.read_parquet('stocknet-dataset/stock_prices.parquet')\n",
    "\n",
    "companies = companies.rename(columns={'symbol': 'ticker'})\n",
    "\n",
    "companies.columns = [x.lower() for x in companies.columns]\n",
    "tweets.columns = [x.lower() for x in tweets.columns]\n",
    "stocks.columns = [x.lower() for x in stocks.columns]\n",
    "\n",
    "tweets['stance_positive'] = (tweets['stance_label'] == 'Positive').astype(int)\n",
    "tweets['stance_negative'] = (tweets['stance_label'] == 'Negative').astype(int)\n",
    "\n",
    "tweets_merged = tweets.groupby(['date', 'ticker'], as_index=False).agg({\n",
    "    'text': lambda x: ' '.join(x),\n",
    "    'sentiment': lambda x: x.mean(),\n",
    "    'emotion_anger': 'sum',\n",
    "    'emotion_disgust': 'sum',\n",
    "    'emotion_fear': 'sum',\n",
    "    'emotion_joy': 'sum',\n",
    "    'emotion_neutral': 'sum',\n",
    "    'emotion_sadness': 'sum',\n",
    "    'emotion_surprize': 'sum',\n",
    "    'stance_positive': 'sum',\n",
    "    'stance_negative': 'sum'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tweets_merged['date'] = pd.to_datetime(tweets_merged['date'])\n",
    "stocks['date'] = pd.to_datetime(stocks['date'])\n",
    "\n",
    "\n",
    "\n",
    "master_df = pd.merge(\n",
    "    stocks,\n",
    "    tweets_merged,\n",
    "    on=[\"date\", \"ticker\"],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing tweet features with 0\n",
    "tweet_feature_cols = ['sentiment', 'emotion_anger', 'emotion_disgust', 'emotion_fear', 'emotion_joy', 'emotion_neutral', 'emotion_sadness', 'emotion_surprize', 'stance_positive', 'stance_negative']\n",
    "for col in tweet_feature_cols:\n",
    "    if col in master_df.columns:\n",
    "        master_df[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "companies = companies.rename(columns={'symbol': 'ticker'})\n",
    "\n",
    "master_df = pd.merge(master_df, companies[['ticker', 'sector', 'company']], on='ticker', how='left')\n",
    "\n",
    "\n",
    "feature_cols = ['open','high','low','volume']\n",
    "\n",
    "master_df = master_df.rename(columns={'close': 'close_price', 'company': 'company_name'})\n",
    "\n",
    "\n",
    "print(f\"Shape of master_df before dropping NaNs: {master_df.shape}\")\n",
    "print(f\"Shape of master_df after dropping NaNs: {master_df.shape}\")\n",
    "\n",
    "master_df.rename(columns={'close_price': 'close'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "master_df.sort_values(by=['ticker', 'date'], inplace=True)\n",
    "\n",
    "\n",
    "def apply_ta_indicators(df_group):\n",
    "    df_group.set_index(pd.DatetimeIndex(df_group['date']), inplace=True)\n",
    "    df_group.ta.ema(length=12, append=True)\n",
    "    df_group.ta.ema(length=26, append=True)\n",
    "    df_group.ta.ema(length=50, append=True)\n",
    "\n",
    "    df_group.ta.macd(fast=12, slow=26, signal=9, append=True)\n",
    "\n",
    "\n",
    "    df_group.ta.rsi(length=14, append=True)\n",
    "    df_group.ta.stochrsi(length=14, append=True)\n",
    "\n",
    "    df_group.ta.atr(length=14, append=True)\n",
    "\n",
    "    bb = ta.bbands(df_group['close'], length=20, std=2)\n",
    "    df_group['BB_upper'] = bb['BBU_20_2.0']\n",
    "    df_group['BB_middle'] = bb['BBM_20_2.0']\n",
    "    df_group['BB_lower'] = bb['BBL_20_2.0']\n",
    "\n",
    "    df_group.ta.obv(append=True)\n",
    "    return df_group.reset_index(drop=True)\n",
    "\n",
    "master_df = master_df.groupby('ticker').apply(apply_ta_indicators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "12_qUQQGGxKm",
    "outputId": "41eb4670-181a-465b-f565-290ccae2d22b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>STOCHRSIk_14_14_3_3</th>\n",
       "      <th>STOCHRSId_14_14_3_3</th>\n",
       "      <th>ATRr_14</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_middle</th>\n",
       "      <th>BB_lower</th>\n",
       "      <th>OBV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-14</td>\n",
       "      <td>77.928574</td>\n",
       "      <td>78.207146</td>\n",
       "      <td>76.597145</td>\n",
       "      <td>76.697144</td>\n",
       "      <td>69.613815</td>\n",
       "      <td>119292600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538077</td>\n",
       "      <td>-3.703588</td>\n",
       "      <td>25.771012</td>\n",
       "      <td>21.054629</td>\n",
       "      <td>19.582354</td>\n",
       "      <td>2.377852</td>\n",
       "      <td>94.648550</td>\n",
       "      <td>84.401357</td>\n",
       "      <td>74.154164</td>\n",
       "      <td>-1.014356e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-15</td>\n",
       "      <td>76.790001</td>\n",
       "      <td>77.071426</td>\n",
       "      <td>74.660004</td>\n",
       "      <td>75.088570</td>\n",
       "      <td>68.153778</td>\n",
       "      <td>197477700.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537725</td>\n",
       "      <td>-3.838019</td>\n",
       "      <td>23.573491</td>\n",
       "      <td>15.792949</td>\n",
       "      <td>19.993462</td>\n",
       "      <td>2.380310</td>\n",
       "      <td>93.761634</td>\n",
       "      <td>83.514428</td>\n",
       "      <td>73.267223</td>\n",
       "      <td>-1.211834e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>75.028572</td>\n",
       "      <td>75.714287</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>75.382858</td>\n",
       "      <td>68.420891</td>\n",
       "      <td>316723400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455544</td>\n",
       "      <td>-3.951905</td>\n",
       "      <td>24.836267</td>\n",
       "      <td>12.243346</td>\n",
       "      <td>16.363641</td>\n",
       "      <td>2.459547</td>\n",
       "      <td>92.716200</td>\n",
       "      <td>82.679214</td>\n",
       "      <td>72.642228</td>\n",
       "      <td>-8.951103e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-19</td>\n",
       "      <td>77.244286</td>\n",
       "      <td>81.071426</td>\n",
       "      <td>77.125717</td>\n",
       "      <td>80.818573</td>\n",
       "      <td>73.354591</td>\n",
       "      <td>205829400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>-3.951213</td>\n",
       "      <td>43.429047</td>\n",
       "      <td>39.692073</td>\n",
       "      <td>22.576123</td>\n",
       "      <td>2.695187</td>\n",
       "      <td>91.617665</td>\n",
       "      <td>82.201285</td>\n",
       "      <td>72.784906</td>\n",
       "      <td>-6.892809e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-20</td>\n",
       "      <td>81.701431</td>\n",
       "      <td>81.707146</td>\n",
       "      <td>79.225716</td>\n",
       "      <td>80.129997</td>\n",
       "      <td>72.729614</td>\n",
       "      <td>160688500.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281964</td>\n",
       "      <td>-3.880722</td>\n",
       "      <td>42.011353</td>\n",
       "      <td>69.373201</td>\n",
       "      <td>40.436207</td>\n",
       "      <td>2.679612</td>\n",
       "      <td>91.027780</td>\n",
       "      <td>81.851785</td>\n",
       "      <td>72.675790</td>\n",
       "      <td>-8.499694e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104215</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>76.940002</td>\n",
       "      <td>76.260002</td>\n",
       "      <td>76.470001</td>\n",
       "      <td>76.470001</td>\n",
       "      <td>8229700.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107548</td>\n",
       "      <td>-0.972858</td>\n",
       "      <td>31.975492</td>\n",
       "      <td>35.117121</td>\n",
       "      <td>31.775404</td>\n",
       "      <td>0.786087</td>\n",
       "      <td>81.525829</td>\n",
       "      <td>78.243500</td>\n",
       "      <td>74.961171</td>\n",
       "      <td>-2.688251e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104216</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>76.209999</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>76.080002</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>7060400.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069077</td>\n",
       "      <td>-0.990127</td>\n",
       "      <td>31.851847</td>\n",
       "      <td>48.597552</td>\n",
       "      <td>38.712818</td>\n",
       "      <td>0.759224</td>\n",
       "      <td>81.303475</td>\n",
       "      <td>78.057500</td>\n",
       "      <td>74.811525</td>\n",
       "      <td>-2.758855e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104217</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>76.239998</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>76.099998</td>\n",
       "      <td>76.099998</td>\n",
       "      <td>8218000.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054652</td>\n",
       "      <td>-1.003790</td>\n",
       "      <td>29.688704</td>\n",
       "      <td>55.025431</td>\n",
       "      <td>46.246701</td>\n",
       "      <td>0.732850</td>\n",
       "      <td>80.964170</td>\n",
       "      <td>77.832500</td>\n",
       "      <td>74.700830</td>\n",
       "      <td>-2.841035e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104218</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>76.269997</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.330002</td>\n",
       "      <td>76.330002</td>\n",
       "      <td>15641700.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018917</td>\n",
       "      <td>-1.008519</td>\n",
       "      <td>32.913052</td>\n",
       "      <td>73.940933</td>\n",
       "      <td>59.187972</td>\n",
       "      <td>0.711932</td>\n",
       "      <td>80.569554</td>\n",
       "      <td>77.624500</td>\n",
       "      <td>74.679446</td>\n",
       "      <td>-2.684618e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104219</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>76.849998</td>\n",
       "      <td>76.320000</td>\n",
       "      <td>76.570000</td>\n",
       "      <td>76.570000</td>\n",
       "      <td>7340800.0</td>\n",
       "      <td>XOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>-1.001273</td>\n",
       "      <td>36.200731</td>\n",
       "      <td>85.986580</td>\n",
       "      <td>71.650981</td>\n",
       "      <td>0.698937</td>\n",
       "      <td>80.167620</td>\n",
       "      <td>77.442500</td>\n",
       "      <td>74.717380</td>\n",
       "      <td>-2.611210e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104220 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close  adj close  \\\n",
       "0      2012-11-14  77.928574  78.207146  76.597145  76.697144  69.613815   \n",
       "1      2012-11-15  76.790001  77.071426  74.660004  75.088570  68.153778   \n",
       "2      2012-11-16  75.028572  75.714287  72.250000  75.382858  68.420891   \n",
       "3      2012-11-19  77.244286  81.071426  77.125717  80.818573  73.354591   \n",
       "4      2012-11-20  81.701431  81.707146  79.225716  80.129997  72.729614   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "104215 2017-08-28  76.900002  76.940002  76.260002  76.470001  76.470001   \n",
       "104216 2017-08-29  76.209999  76.489998  76.080002  76.449997  76.449997   \n",
       "104217 2017-08-30  76.239998  76.449997  76.059998  76.099998  76.099998   \n",
       "104218 2017-08-31  76.269997  76.489998  76.050003  76.330002  76.330002   \n",
       "104219 2017-09-01  76.370003  76.849998  76.320000  76.570000  76.570000   \n",
       "\n",
       "             volume ticker text  sentiment  ...  MACDh_12_26_9  MACDs_12_26_9  \\\n",
       "0       119292600.0   AAPL  NaN        0.0  ...      -0.538077      -3.703588   \n",
       "1       197477700.0   AAPL  NaN        0.0  ...      -0.537725      -3.838019   \n",
       "2       316723400.0   AAPL  NaN        0.0  ...      -0.455544      -3.951905   \n",
       "3       205829400.0   AAPL  NaN        0.0  ...       0.002769      -3.951213   \n",
       "4       160688500.0   AAPL  NaN        0.0  ...       0.281964      -3.880722   \n",
       "...             ...    ...  ...        ...  ...            ...            ...   \n",
       "104215    8229700.0    XOM  NaN        0.0  ...      -0.107548      -0.972858   \n",
       "104216    7060400.0    XOM  NaN        0.0  ...      -0.069077      -0.990127   \n",
       "104217    8218000.0    XOM  NaN        0.0  ...      -0.054652      -1.003790   \n",
       "104218   15641700.0    XOM  NaN        0.0  ...      -0.018917      -1.008519   \n",
       "104219    7340800.0    XOM  NaN        0.0  ...       0.028984      -1.001273   \n",
       "\n",
       "           RSI_14  STOCHRSIk_14_14_3_3  STOCHRSId_14_14_3_3   ATRr_14  \\\n",
       "0       25.771012            21.054629            19.582354  2.377852   \n",
       "1       23.573491            15.792949            19.993462  2.380310   \n",
       "2       24.836267            12.243346            16.363641  2.459547   \n",
       "3       43.429047            39.692073            22.576123  2.695187   \n",
       "4       42.011353            69.373201            40.436207  2.679612   \n",
       "...           ...                  ...                  ...       ...   \n",
       "104215  31.975492            35.117121            31.775404  0.786087   \n",
       "104216  31.851847            48.597552            38.712818  0.759224   \n",
       "104217  29.688704            55.025431            46.246701  0.732850   \n",
       "104218  32.913052            73.940933            59.187972  0.711932   \n",
       "104219  36.200731            85.986580            71.650981  0.698937   \n",
       "\n",
       "         BB_upper  BB_middle   BB_lower           OBV  \n",
       "0       94.648550  84.401357  74.154164 -1.014356e+09  \n",
       "1       93.761634  83.514428  73.267223 -1.211834e+09  \n",
       "2       92.716200  82.679214  72.642228 -8.951103e+08  \n",
       "3       91.617665  82.201285  72.784906 -6.892809e+08  \n",
       "4       91.027780  81.851785  72.675790 -8.499694e+08  \n",
       "...           ...        ...        ...           ...  \n",
       "104215  81.525829  78.243500  74.961171 -2.688251e+08  \n",
       "104216  81.303475  78.057500  74.811525 -2.758855e+08  \n",
       "104217  80.964170  77.832500  74.700830 -2.841035e+08  \n",
       "104218  80.569554  77.624500  74.679446 -2.684618e+08  \n",
       "104219  80.167620  77.442500  74.717380 -2.611210e+08  \n",
       "\n",
       "[104220 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_check = ['EMA_12', 'EMA_26','EMA_50','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9','RSI_14','ATRr_14','STOCHRSIk_14_14_3_3','STOCHRSId_14_14_3_3','ATRr_14','BB_upper','BB_middle','BB_lower','OBV']\n",
    "master_df = master_df.dropna(subset=columns_to_check)\n",
    "\n",
    "\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4D6EfvoYDrGY",
    "outputId": "a09ae550-5787-45c6-81aa-4bf74311f09f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'open', 'high', 'low', 'close', 'adj close', 'volume', 'ticker',\n",
      "       'text', 'sentiment', 'emotion_anger', 'emotion_disgust', 'emotion_fear',\n",
      "       'emotion_joy', 'emotion_neutral', 'emotion_sadness', 'emotion_surprize',\n",
      "       'stance_positive', 'stance_negative', 'sector', 'company_name',\n",
      "       'EMA_12', 'EMA_26', 'EMA_50', 'MACD_12_26_9', 'MACDh_12_26_9',\n",
      "       'MACDs_12_26_9', 'RSI_14', 'STOCHRSIk_14_14_3_3', 'STOCHRSId_14_14_3_3',\n",
      "       'ATRr_14', 'BB_upper', 'BB_middle', 'BB_lower', 'OBV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(master_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ytoycwxUDtS3"
   },
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'open', 'high', 'low', 'close', 'volume'\n",
    "    # 'stance_positive', 'stance_negative',\n",
    "    # 'sentiment'\n",
    "]\n",
    "\n",
    "new_indicator_columns = [\n",
    "    'EMA_12', 'EMA_26', 'EMA_50', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "    'RSI_14', 'ATRr_14', 'STOCHRSIk_14_14_3_3', 'STOCHRSId_14_14_3_3',\n",
    "    'BB_upper', 'BB_middle', 'BB_lower', 'OBV'\n",
    "]\n",
    "feature_columns.extend(new_indicator_columns)\n",
    "\n",
    "sequence_length=12\n",
    "\n",
    "\n",
    "\n",
    "all_pipelines = {}\n",
    "all_results_dfs = {}\n",
    "all_analyses = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RBV6cWZNDuCW",
    "outputId": "07c614de-47f3-4115-a4f2-0a8e11405f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "  RUNNING PIPELINE FOR: LSTM\n",
      "=========================\n",
      "\n",
      "Pipeline initialized for a 'multiclass' problem with horizon 1 steps. Device: cpu\n",
      "Processing 88 companies with LSTM model...\n",
      "Problem type: multiclass\n",
      "Sequence length: 12\n",
      "Features: ['open', 'high', 'low', 'close', 'volume', 'EMA_12', 'EMA_26', 'EMA_50', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'RSI_14', 'ATRr_14', 'STOCHRSIk_14_14_3_3', 'STOCHRSId_14_14_3_3', 'BB_upper', 'BB_middle', 'BB_lower', 'OBV']\n",
      "\n",
      "[1/88] Processing AAPL...\n",
      "\n",
      "Processing AAPL (Consumer Goods)...\n",
      "  Epoch 010 - train 0.79862 | val 0.81705\n",
      "  Epoch 020 - train 0.67884 | val 0.81993\n",
      "  Epoch 029 - train 0.58641 | val 0.87788\n",
      "  Multiclass -> Micro Acc: 0.4271, Macro F1: 0.3633, Expected Return: -0.006850\n",
      "\n",
      "[2/88] Processing ABB...\n",
      "\n",
      "Processing ABB (Industrial Goods)...\n",
      "  Epoch 010 - train 0.70042 | val 1.90089\n",
      "  Epoch 017 - train 0.64597 | val 1.89935\n",
      "  Multiclass -> Micro Acc: 0.4975, Macro F1: 0.3322, Expected Return: -0.008162\n",
      "\n",
      "[3/88] Processing ABBV...\n",
      "\n",
      "Processing ABBV (Healthcare)...\n",
      "  Epoch 010 - train 0.75309 | val 0.71598\n",
      "  Epoch 020 - train 0.67181 | val 0.85004\n",
      "  Epoch 025 - train 0.64084 | val 0.88534\n",
      "  Multiclass -> Micro Acc: 0.4270, Macro F1: 0.3669, Expected Return: -0.004317\n",
      "\n",
      "[4/88] Processing AEP...\n",
      "\n",
      "Processing AEP (Utilities)...\n",
      "  Epoch 010 - train 0.68796 | val 0.80703\n",
      "  Epoch 020 - train 0.63478 | val 0.93595\n",
      "  Epoch 027 - train 0.59716 | val 1.06089\n",
      "  Multiclass -> Micro Acc: 0.4523, Macro F1: 0.3402, Expected Return: -0.003750\n",
      "\n",
      "[5/88] Processing AGFS...\n",
      "\n",
      "Processing AGFS (Conglomerates)...\n",
      "  Epoch 010 - train 1.06962 | val 2.72686\n",
      "  Epoch 018 - train 0.76999 | val 3.20232\n",
      "  Multiclass -> Micro Acc: 0.4340, Macro F1: 0.1594, Expected Return: -0.033999\n",
      "\n",
      "[6/88] Processing AMGN...\n",
      "\n",
      "Processing AMGN (Healthcare)...\n",
      "  Epoch 010 - train 0.68119 | val 2.07838\n",
      "  Epoch 017 - train 0.63183 | val 2.10494\n",
      "  Multiclass -> Micro Acc: 0.4573, Macro F1: 0.4088, Expected Return: -0.001519\n",
      "\n",
      "[7/88] Processing AMZN...\n",
      "\n",
      "Processing AMZN (Services)...\n",
      "  Epoch 010 - train 1.01234 | val 1.30347\n",
      "  Epoch 020 - train 0.60932 | val 1.83924\n",
      "  Epoch 030 - train 0.52288 | val 1.40689\n",
      "  Multiclass -> Micro Acc: 0.5578, Macro F1: 0.3581, Expected Return: 0.006615\n",
      "\n",
      "[8/88] Processing BA...\n",
      "\n",
      "Processing BA (Industrial Goods)...\n",
      "  Epoch 010 - train 0.70211 | val 0.71272\n",
      "  Epoch 020 - train 0.62638 | val 0.73146\n",
      "  Epoch 026 - train 0.56060 | val 0.83759\n",
      "  Multiclass -> Micro Acc: 0.3920, Macro F1: 0.1877, Expected Return: -0.008169\n",
      "\n",
      "[9/88] Processing BABA...\n",
      "\n",
      "Processing BABA (Services)...\n",
      "  Epoch 010 - train 0.95613 | val 0.88032\n",
      "  Epoch 020 - train 0.65871 | val 1.21331\n",
      "  Multiclass -> Micro Acc: 0.4248, Macro F1: 0.1988, Expected Return: -0.009864\n",
      "\n",
      "[10/88] Processing BAC...\n",
      "\n",
      "Processing BAC (Financial)...\n",
      "  Epoch 010 - train 0.68307 | val 0.73031\n",
      "  Epoch 020 - train 0.63577 | val 0.94102\n",
      "  Epoch 022 - train 0.62424 | val 1.03458\n",
      "  Multiclass -> Micro Acc: 0.5377, Macro F1: 0.3497, Expected Return: -0.008687\n",
      "\n",
      "[11/88] Processing BBL...\n",
      "\n",
      "Processing BBL (Basic Matierials)...\n",
      "  Epoch 010 - train 0.88425 | val 4.15406\n",
      "  Epoch 017 - train 0.72629 | val 4.56210\n",
      "  Multiclass -> Micro Acc: 0.5477, Macro F1: 0.5210, Expected Return: 0.001730\n",
      "\n",
      "[12/88] Processing BCH...\n",
      "\n",
      "Processing BCH (Financial)...\n",
      "  Epoch 010 - train 0.65752 | val 0.74602\n",
      "  Epoch 020 - train 0.61761 | val 0.74197\n",
      "  Epoch 030 - train 0.58866 | val 0.76441\n",
      "  Multiclass -> Micro Acc: 0.4824, Macro F1: 0.4379, Expected Return: -0.004440\n",
      "\n",
      "[13/88] Processing BHP...\n",
      "\n",
      "Processing BHP (Basic Matierials)...\n",
      "  Epoch 010 - train 0.74886 | val 2.84151\n",
      "  Epoch 017 - train 0.64073 | val 3.00248\n",
      "  Multiclass -> Micro Acc: 0.4472, Macro F1: 0.3308, Expected Return: 0.004956\n",
      "\n",
      "[14/88] Processing BP...\n",
      "\n",
      "Processing BP (Basic Matierials)...\n",
      "  Epoch 010 - train 0.82319 | val 0.72764\n",
      "  Epoch 020 - train 0.62606 | val 0.78431\n",
      "  Epoch 030 - train 0.61469 | val 0.98456\n",
      "  Epoch 031 - train 0.55729 | val 1.01133\n",
      "  Multiclass -> Micro Acc: 0.4975, Macro F1: 0.4946, Expected Return: 0.002202\n",
      "\n",
      "[15/88] Processing BRK-A...\n",
      "\n",
      "Processing BRK-A (Financial)...\n",
      "  Epoch 010 - train 0.68034 | val 0.77261\n",
      "  Epoch 020 - train 0.62506 | val 0.84728\n",
      "  Epoch 023 - train 0.62202 | val 0.92917\n",
      "  Multiclass -> Micro Acc: 0.4673, Macro F1: 0.4197, Expected Return: -0.001111\n",
      "\n",
      "[16/88] Processing BSAC...\n",
      "\n",
      "Processing BSAC (Financial)...\n",
      "  Epoch 010 - train 0.67364 | val 0.80536\n",
      "  Epoch 020 - train 0.60703 | val 1.36330\n",
      "  Epoch 024 - train 0.60440 | val 1.20280\n",
      "  Multiclass -> Micro Acc: 0.5176, Macro F1: 0.5122, Expected Return: -0.000195\n",
      "\n",
      "[17/88] Processing BUD...\n",
      "\n",
      "Processing BUD (Consumer Goods)...\n",
      "  Epoch 010 - train 0.65485 | val 0.74099\n",
      "  Epoch 020 - train 0.64366 | val 0.72613\n",
      "  Epoch 028 - train 0.58912 | val 0.82250\n",
      "  Multiclass -> Micro Acc: 0.5578, Macro F1: 0.3581, Expected Return: 0.009253\n",
      "\n",
      "[18/88] Processing C...\n",
      "\n",
      "Processing C (Financial)...\n",
      "  Epoch 010 - train 0.66947 | val 2.47880\n",
      "  Epoch 016 - train 0.64122 | val 2.63408\n",
      "  Multiclass -> Micro Acc: 0.4824, Macro F1: 0.3254, Expected Return: -0.001371\n",
      "\n",
      "[19/88] Processing CAT...\n",
      "\n",
      "Processing CAT (Industrial Goods)...\n",
      "  Epoch 010 - train 0.70112 | val 0.71817\n",
      "  Epoch 020 - train 0.63234 | val 0.79061\n",
      "  Epoch 029 - train 0.58494 | val 0.86199\n",
      "  Multiclass -> Micro Acc: 0.4673, Macro F1: 0.4634, Expected Return: -0.000964\n",
      "\n",
      "[20/88] Processing CELG...\n",
      "\n",
      "Processing CELG (Healthcare)...\n",
      "  Epoch 010 - train 0.81130 | val 0.93385\n",
      "  Epoch 020 - train 0.63345 | val 0.89329\n",
      "  Epoch 030 - train 0.57985 | val 0.93845\n",
      "  Multiclass -> Micro Acc: 0.4422, Macro F1: 0.3470, Expected Return: -0.007224\n",
      "\n",
      "[21/88] Processing CHL...\n",
      "\n",
      "Processing CHL (Technology)...\n",
      "  Epoch 010 - train 0.68136 | val 0.74440\n",
      "  Epoch 020 - train 0.63154 | val 0.80676\n",
      "  Epoch 022 - train 0.62788 | val 0.83109\n",
      "  Multiclass -> Micro Acc: 0.4925, Macro F1: 0.3300, Expected Return: 0.005179\n",
      "\n",
      "[22/88] Processing CHTR...\n",
      "\n",
      "Processing CHTR (Services)...\n",
      "  Epoch 010 - train 0.78800 | val 2.27737\n",
      "  Epoch 016 - train 0.74989 | val 2.42316\n",
      "  Multiclass -> Micro Acc: 0.4372, Macro F1: 0.3042, Expected Return: 0.011122\n",
      "\n",
      "[23/88] Processing CMCSA...\n",
      "\n",
      "Processing CMCSA (Services)...\n",
      "  Epoch 010 - train 0.68537 | val 0.90654\n",
      "  Epoch 020 - train 0.62854 | val 1.10880\n",
      "  Multiclass -> Micro Acc: 0.4573, Macro F1: 0.3138, Expected Return: -0.004798\n",
      "\n",
      "[24/88] Processing CODI...\n",
      "\n",
      "Processing CODI (Conglomerates)...\n",
      "  Epoch 010 - train 0.67047 | val 0.71279\n",
      "  Epoch 020 - train 0.62958 | val 0.78861\n",
      "  Epoch 028 - train 0.57133 | val 0.84236\n",
      "  Multiclass -> Micro Acc: 0.5327, Macro F1: 0.5322, Expected Return: 0.000927\n",
      "\n",
      "[25/88] Processing CSCO...\n",
      "\n",
      "Processing CSCO (Technology)...\n",
      "  Epoch 010 - train 0.80405 | val 1.89066\n",
      "  Epoch 018 - train 0.69817 | val 2.41292\n",
      "  Multiclass -> Micro Acc: 0.4774, Macro F1: 0.3231, Expected Return: -0.006110\n",
      "\n",
      "[26/88] Processing CVX...\n",
      "\n",
      "Processing CVX (Basic Matierials)...\n",
      "  Epoch 010 - train 0.67543 | val 0.74854\n",
      "  Epoch 020 - train 0.62202 | val 0.72270\n",
      "  Epoch 030 - train 0.59982 | val 0.73819\n",
      "  Epoch 040 - train 0.57374 | val 0.78723\n",
      "  Epoch 041 - train 0.56190 | val 0.79318\n",
      "  Multiclass -> Micro Acc: 0.5628, Macro F1: 0.5552, Expected Return: -0.000965\n",
      "\n",
      "[27/88] Processing D...\n",
      "\n",
      "Processing D (Utilities)...\n",
      "  Epoch 010 - train 0.66776 | val 1.28268\n",
      "  Epoch 018 - train 0.61125 | val 2.28483\n",
      "  Multiclass -> Micro Acc: 0.4573, Macro F1: 0.3138, Expected Return: -0.004735\n",
      "\n",
      "[28/88] Processing DHR...\n",
      "\n",
      "Processing DHR (Industrial Goods)...\n",
      "  Epoch 010 - train 0.69317 | val 0.79909\n",
      "  Epoch 020 - train 0.63820 | val 0.91503\n",
      "  Multiclass -> Micro Acc: 0.5025, Macro F1: 0.3344, Expected Return: -0.001257\n",
      "\n",
      "[29/88] Processing DIS...\n",
      "\n",
      "Processing DIS (Services)...\n",
      "  Epoch 010 - train 0.79315 | val 1.16455\n",
      "  Epoch 020 - train 0.64240 | val 1.09289\n",
      "  Epoch 023 - train 0.67511 | val 1.34044\n",
      "  Multiclass -> Micro Acc: 0.5126, Macro F1: 0.5094, Expected Return: -0.001189\n",
      "\n",
      "[30/88] Processing DUK...\n",
      "\n",
      "Processing DUK (Utilities)...\n",
      "  Epoch 010 - train 0.67781 | val 1.03882\n",
      "  Epoch 018 - train 0.64200 | val 1.12721\n",
      "  Multiclass -> Micro Acc: 0.4523, Macro F1: 0.3114, Expected Return: -0.003595\n",
      "\n",
      "[31/88] Processing EXC...\n",
      "\n",
      "Processing EXC (Utilities)...\n",
      "  Epoch 010 - train 0.70201 | val 0.76806\n",
      "  Epoch 020 - train 0.63831 | val 0.78748\n",
      "  Epoch 030 - train 0.59516 | val 0.89953\n",
      "  Epoch 031 - train 0.57574 | val 0.90923\n",
      "  Multiclass -> Micro Acc: 0.4925, Macro F1: 0.3300, Expected Return: -0.003734\n",
      "\n",
      "[32/88] Processing FB...\n",
      "\n",
      "Processing FB (Technology)...\n",
      "  Epoch 010 - train 1.01250 | val 0.71664\n",
      "  Epoch 020 - train 0.73720 | val 0.71634\n",
      "  Epoch 030 - train 0.67380 | val 0.71040\n",
      "  Epoch 036 - train 0.59952 | val 0.74475\n",
      "  Multiclass -> Micro Acc: 0.4874, Macro F1: 0.4837, Expected Return: 0.000748\n",
      "\n",
      "[33/88] Processing GD...\n",
      "\n",
      "Processing GD (Industrial Goods)...\n",
      "  Epoch 010 - train 0.69027 | val 0.73985\n",
      "  Epoch 020 - train 0.62894 | val 0.76041\n",
      "  Epoch 023 - train 0.63610 | val 0.83163\n",
      "  Multiclass -> Micro Acc: 0.4121, Macro F1: 0.3789, Expected Return: -0.000881\n",
      "\n",
      "[34/88] Processing GE...\n",
      "\n",
      "Processing GE (Industrial Goods)...\n",
      "  Epoch 010 - train 0.71153 | val 0.78422\n",
      "  Epoch 020 - train 0.61809 | val 0.99921\n",
      "  Epoch 022 - train 0.61993 | val 1.00280\n",
      "  Multiclass -> Micro Acc: 0.5327, Macro F1: 0.4478, Expected Return: -0.001178\n",
      "\n",
      "[35/88] Processing GMRE...\n",
      "\n",
      "Processing GMRE (Conglomerates)...\n",
      "  Epoch 010 - train 0.91104 | val 1.11119\n",
      "  Epoch 020 - train 0.57668 | val 1.38039\n",
      "  Epoch 026 - train 0.48217 | val 1.54579\n",
      "  Multiclass -> Micro Acc: 0.2340, Macro F1: 0.1122, Expected Return: 0.005384\n",
      "\n",
      "[36/88] Processing GOOG...\n",
      "\n",
      "Processing GOOG (Technology)...\n",
      "  Epoch 010 - train 0.77488 | val 0.89502\n",
      "  Epoch 020 - train 0.69895 | val 0.86513\n",
      "  Multiclass -> Micro Acc: 0.4322, Macro F1: 0.3520, Expected Return: -0.003152\n",
      "\n",
      "[37/88] Processing HD...\n",
      "\n",
      "Processing HD (Services)...\n",
      "  Epoch 010 - train 0.68102 | val 0.93316\n",
      "  Epoch 018 - train 0.64378 | val 0.87731\n",
      "  Multiclass -> Micro Acc: 0.5025, Macro F1: 0.3947, Expected Return: -0.003229\n",
      "\n",
      "[38/88] Processing HON...\n",
      "\n",
      "Processing HON (Industrial Goods)...\n",
      "  Epoch 010 - train 0.68156 | val 1.07848\n",
      "  Epoch 018 - train 0.64485 | val 1.72760\n",
      "  Multiclass -> Micro Acc: 0.4322, Macro F1: 0.3018, Expected Return: -0.005136\n",
      "\n",
      "[39/88] Processing HRG...\n",
      "\n",
      "Processing HRG (Conglomerates)...\n",
      "  Epoch 010 - train 0.72514 | val 2.06352\n",
      "  Epoch 017 - train 0.66113 | val 2.43937\n",
      "  Multiclass -> Micro Acc: 0.4372, Macro F1: 0.2186, Expected Return: -0.028244\n",
      "\n",
      "[40/88] Processing HSBC...\n",
      "\n",
      "Processing HSBC (Financial)...\n",
      "  Epoch 010 - train 0.68358 | val 2.49229\n",
      "  Epoch 017 - train 0.66024 | val 4.01788\n",
      "  Multiclass -> Micro Acc: 0.5427, Macro F1: 0.5169, Expected Return: 0.000425\n",
      "\n",
      "[41/88] Processing IEP...\n",
      "\n",
      "Processing IEP (Conglomerates)...\n",
      "  Epoch 010 - train 0.88002 | val 2.13458\n",
      "  Epoch 018 - train 0.69624 | val 2.46618\n",
      "  Multiclass -> Micro Acc: 0.5126, Macro F1: 0.3422, Expected Return: 0.001571\n",
      "\n",
      "[42/88] Processing INTC...\n",
      "\n",
      "Processing INTC (Technology)...\n",
      "  Epoch 010 - train 0.81203 | val 0.98558\n",
      "  Epoch 020 - train 0.67566 | val 0.98278\n",
      "  Multiclass -> Micro Acc: 0.4573, Macro F1: 0.3138, Expected Return: -0.004569\n",
      "\n",
      "[43/88] Processing JNJ...\n",
      "\n",
      "Processing JNJ (Healthcare)...\n",
      "  Epoch 010 - train 0.67970 | val 1.20007\n",
      "  Epoch 017 - train 0.64857 | val 1.36351\n",
      "  Multiclass -> Micro Acc: 0.4874, Macro F1: 0.3277, Expected Return: -0.002634\n",
      "\n",
      "[44/88] Processing JPM...\n",
      "\n",
      "Processing JPM (Financial)...\n",
      "  Epoch 010 - train 0.68862 | val 2.22503\n",
      "  Epoch 017 - train 0.64735 | val 1.97556\n",
      "  Multiclass -> Micro Acc: 0.4774, Macro F1: 0.3231, Expected Return: -0.005178\n",
      "\n",
      "[45/88] Processing KO...\n",
      "\n",
      "Processing KO (Consumer Goods)...\n",
      "  Epoch 010 - train 0.66804 | val 1.86082\n",
      "  Epoch 017 - train 0.61116 | val 2.89638\n",
      "  Multiclass -> Micro Acc: 0.4925, Macro F1: 0.4110, Expected Return: -0.001758\n",
      "\n",
      "[46/88] Processing LMT...\n",
      "\n",
      "Processing LMT (Industrial Goods)...\n",
      "  Epoch 010 - train 0.68790 | val 0.79387\n",
      "  Epoch 020 - train 0.63262 | val 1.01284\n",
      "  Epoch 025 - train 0.61572 | val 1.14117\n",
      "  Multiclass -> Micro Acc: 0.4121, Macro F1: 0.2918, Expected Return: -0.003643\n",
      "\n",
      "[47/88] Processing MA...\n",
      "\n",
      "Processing MA (Financial)...\n",
      "  Epoch 010 - train 0.66798 | val 0.81430\n",
      "  Epoch 020 - train 0.66180 | val 0.84556\n",
      "  Multiclass -> Micro Acc: 0.4372, Macro F1: 0.3116, Expected Return: -0.002594\n",
      "\n",
      "[48/88] Processing MCD...\n",
      "\n",
      "Processing MCD (Services)...\n",
      "  Epoch 010 - train 0.72733 | val 1.60138\n",
      "  Epoch 017 - train 0.65851 | val 2.91306\n",
      "  Multiclass -> Micro Acc: 0.3970, Macro F1: 0.2842, Expected Return: -0.002284\n",
      "\n",
      "[49/88] Processing MDT...\n",
      "\n",
      "Processing MDT (Healthcare)...\n",
      "  Epoch 010 - train 0.69857 | val 0.91406\n",
      "  Epoch 018 - train 0.65785 | val 1.05934\n",
      "  Multiclass -> Micro Acc: 0.5477, Macro F1: 0.3540, Expected Return: -0.000807\n",
      "\n",
      "[50/88] Processing MMM...\n",
      "\n",
      "Processing MMM (Industrial Goods)...\n",
      "  Epoch 010 - train 0.68643 | val 0.88762\n",
      "  Epoch 020 - train 0.62081 | val 1.06635\n",
      "  Epoch 025 - train 0.60348 | val 1.07364\n",
      "  Multiclass -> Micro Acc: 0.4322, Macro F1: 0.3018, Expected Return: -0.006017\n",
      "\n",
      "[51/88] Processing MO...\n",
      "\n",
      "Processing MO (Consumer Goods)...\n",
      "  Epoch 010 - train 0.70014 | val 0.80832\n",
      "  Epoch 019 - train 0.63938 | val 0.91511\n",
      "  Multiclass -> Micro Acc: 0.4221, Macro F1: 0.2158, Expected Return: -0.001689\n",
      "\n",
      "[52/88] Processing MRK...\n",
      "\n",
      "Processing MRK (Healthcare)...\n",
      "  Epoch 010 - train 0.67942 | val 2.11827\n",
      "  Epoch 017 - train 0.62942 | val 2.37743\n",
      "  Multiclass -> Micro Acc: 0.4925, Macro F1: 0.3300, Expected Return: -0.002784\n",
      "\n",
      "[53/88] Processing MSFT...\n",
      "\n",
      "Processing MSFT (Technology)...\n",
      "  Epoch 010 - train 0.95569 | val 0.81036\n",
      "  Epoch 019 - train 0.70184 | val 0.90918\n",
      "  Multiclass -> Micro Acc: 0.4874, Macro F1: 0.3277, Expected Return: -0.001253\n",
      "\n",
      "[54/88] Processing NEE...\n",
      "\n",
      "Processing NEE (Utilities)...\n",
      "  Epoch 010 - train 0.66696 | val 1.53806\n",
      "  Epoch 017 - train 0.62669 | val 1.85430\n",
      "  Multiclass -> Micro Acc: 0.4020, Macro F1: 0.2867, Expected Return: -0.004580\n",
      "\n",
      "[55/88] Processing NGG...\n",
      "\n",
      "Processing NGG (Utilities)...\n",
      "  Epoch 010 - train 0.69395 | val 0.79393\n",
      "  Epoch 020 - train 0.63562 | val 0.81099\n",
      "  Epoch 023 - train 0.62847 | val 0.81612\n",
      "  Multiclass -> Micro Acc: 0.4975, Macro F1: 0.4526, Expected Return: 0.003821\n",
      "\n",
      "[56/88] Processing NVS...\n",
      "\n",
      "Processing NVS (Healthcare)...\n",
      "  Epoch 010 - train 0.67382 | val 1.01733\n",
      "  Epoch 017 - train 0.63123 | val 1.01529\n",
      "  Multiclass -> Micro Acc: 0.4774, Macro F1: 0.4751, Expected Return: -0.000140\n",
      "\n",
      "[57/88] Processing ORCL...\n",
      "\n",
      "Processing ORCL (Technology)...\n",
      "  Epoch 010 - train 0.87154 | val 0.75621\n",
      "  Epoch 020 - train 0.64313 | val 0.84886\n",
      "  Epoch 023 - train 0.57529 | val 0.88575\n",
      "  Multiclass -> Micro Acc: 0.4724, Macro F1: 0.2749, Expected Return: -0.001991\n",
      "\n",
      "[58/88] Processing PCG...\n",
      "\n",
      "Processing PCG (Utilities)...\n",
      "  Epoch 010 - train 0.68002 | val 0.79825\n",
      "  Epoch 020 - train 0.62644 | val 0.84723\n",
      "  Epoch 021 - train 0.60721 | val 0.85809\n",
      "  Multiclass -> Micro Acc: 0.4724, Macro F1: 0.3367, Expected Return: -0.002763\n",
      "\n",
      "[59/88] Processing PCLN...\n",
      "\n",
      "Processing PCLN (Services)...\n",
      "  Epoch 010 - train 0.92978 | val 1.94639\n",
      "  Epoch 017 - train 0.78998 | val 2.20302\n",
      "  Multiclass -> Micro Acc: 0.4422, Macro F1: 0.3582, Expected Return: -0.011269\n",
      "\n",
      "[60/88] Processing PEP...\n",
      "\n",
      "Processing PEP (Consumer Goods)...\n",
      "  Epoch 010 - train 0.65608 | val 1.05172\n",
      "  Epoch 020 - train 0.60907 | val 1.46946\n",
      "  Multiclass -> Micro Acc: 0.4724, Macro F1: 0.3367, Expected Return: -0.003342\n",
      "\n",
      "[61/88] Processing PFE...\n",
      "\n",
      "Processing PFE (Healthcare)...\n",
      "  Epoch 010 - train 0.67425 | val 0.88504\n",
      "  Epoch 020 - train 0.63892 | val 0.88378\n",
      "  Epoch 030 - train 0.58692 | val 0.96581\n",
      "  Multiclass -> Micro Acc: 0.5075, Macro F1: 0.4446, Expected Return: 0.004437\n",
      "\n",
      "[62/88] Processing PG...\n",
      "\n",
      "Processing PG (Consumer Goods)...\n",
      "  Epoch 010 - train 0.66836 | val 1.25150\n",
      "  Epoch 018 - train 0.62170 | val 1.14782\n",
      "  Multiclass -> Micro Acc: 0.4874, Macro F1: 0.3277, Expected Return: -0.005394\n",
      "\n",
      "[63/88] Processing PICO...\n",
      "\n",
      "Processing PICO (Conglomerates)...\n",
      "  Epoch 010 - train 0.76557 | val 4.07390\n",
      "  Epoch 016 - train 0.67114 | val 4.78830\n",
      "  Multiclass -> Micro Acc: 0.4824, Macro F1: 0.4413, Expected Return: 0.011511\n",
      "\n",
      "[64/88] Processing PM...\n",
      "\n",
      "Processing PM (Consumer Goods)...\n",
      "  Epoch 010 - train 0.78169 | val 0.88345\n",
      "  Epoch 020 - train 0.61869 | val 0.87388\n",
      "  Epoch 027 - train 0.56807 | val 1.08592\n",
      "  Multiclass -> Micro Acc: 0.4673, Macro F1: 0.4037, Expected Return: -0.002846\n",
      "\n",
      "[65/88] Processing PPL...\n",
      "\n",
      "Processing PPL (Utilities)...\n",
      "  Epoch 010 - train 0.67883 | val 1.15673\n",
      "  Epoch 018 - train 0.62743 | val 1.42509\n",
      "  Multiclass -> Micro Acc: 0.4372, Macro F1: 0.3381, Expected Return: -0.004249\n",
      "\n",
      "[66/88] Processing PTR...\n",
      "\n",
      "Processing PTR (Basic Matierials)...\n",
      "  Epoch 010 - train 0.65889 | val 1.56279\n",
      "  Epoch 017 - train 0.61764 | val 1.92125\n",
      "  Multiclass -> Micro Acc: 0.4439, Macro F1: 0.2967, Expected Return: 0.000354\n",
      "\n",
      "[67/88] Processing RDS-B...\n",
      "\n",
      "Processing RDS-B (Basic Matierials)...\n",
      "  Epoch 010 - train 0.68711 | val 1.43616\n",
      "  Epoch 018 - train 0.64525 | val 1.83904\n",
      "  Multiclass -> Micro Acc: 0.5226, Macro F1: 0.5209, Expected Return: -0.001345\n",
      "\n",
      "[68/88] Processing REX...\n",
      "\n",
      "Processing REX (Conglomerates)...\n",
      "  Epoch 010 - train 1.16908 | val 1.41434\n",
      "  Epoch 018 - train 0.94742 | val 1.47177\n",
      "  Multiclass -> Micro Acc: 0.4694, Macro F1: 0.4638, Expected Return: -0.000503\n",
      "\n",
      "[69/88] Processing SLB...\n",
      "\n",
      "Processing SLB (Basic Matierials)...\n",
      "  Epoch 010 - train 0.68530 | val 0.97530\n",
      "  Epoch 020 - train 0.63361 | val 1.19739\n",
      "  Epoch 023 - train 0.62586 | val 1.15579\n",
      "  Multiclass -> Micro Acc: 0.4372, Macro F1: 0.3042, Expected Return: 0.006434\n",
      "\n",
      "[70/88] Processing SNP...\n",
      "\n",
      "Processing SNP (Basic Matierials)...\n",
      "  Epoch 010 - train 0.76750 | val 1.11694\n",
      "  Epoch 019 - train 0.65051 | val 1.40736\n",
      "  Multiclass -> Micro Acc: 0.5102, Macro F1: 0.3469, Expected Return: -0.006645\n",
      "\n",
      "[71/88] Processing SNY...\n",
      "\n",
      "Processing SNY (Healthcare)...\n",
      "  Epoch 010 - train 0.75180 | val 0.74821\n",
      "  Epoch 020 - train 0.61524 | val 0.93668\n",
      "  Epoch 025 - train 0.62949 | val 0.87610\n",
      "  Multiclass -> Micro Acc: 0.5377, Macro F1: 0.4703, Expected Return: 0.001095\n",
      "\n",
      "[72/88] Processing SO...\n",
      "\n",
      "Processing SO (Utilities)...\n",
      "  Epoch 010 - train 0.69014 | val 1.28406\n",
      "  Epoch 020 - train 0.62604 | val 2.05694\n",
      "  Multiclass -> Micro Acc: 0.4874, Macro F1: 0.3277, Expected Return: -0.004028\n",
      "\n",
      "[73/88] Processing SPLP...\n",
      "\n",
      "Processing SPLP (Conglomerates)...\n",
      "  Epoch 010 - train 0.85417 | val 0.86896\n",
      "  Epoch 019 - train 0.69587 | val 1.01203\n",
      "  Multiclass -> Micro Acc: 0.5829, Macro F1: 0.5201, Expected Return: 0.000420\n",
      "\n",
      "[74/88] Processing SRE...\n",
      "\n",
      "Processing SRE (Utilities)...\n",
      "  Epoch 010 - train 0.68894 | val 0.80526\n",
      "  Epoch 020 - train 0.65905 | val 0.81873\n",
      "  Epoch 026 - train 0.63464 | val 0.82838\n",
      "  Multiclass -> Micro Acc: 0.5025, Macro F1: 0.4176, Expected Return: -0.002657\n",
      "\n",
      "[75/88] Processing T...\n",
      "\n",
      "Processing T (Technology)...\n",
      "  Epoch 010 - train 0.66135 | val 1.73403\n",
      "  Epoch 020 - train 0.60950 | val 1.58966\n",
      "  Epoch 026 - train 0.58411 | val 1.37779\n",
      "  Multiclass -> Micro Acc: 0.5226, Macro F1: 0.5065, Expected Return: -0.003736\n",
      "\n",
      "[76/88] Processing TM...\n",
      "\n",
      "Processing TM (Consumer Goods)...\n",
      "  Epoch 010 - train 0.67247 | val 1.10896\n",
      "  Epoch 018 - train 0.61380 | val 1.57951\n",
      "  Multiclass -> Micro Acc: 0.4975, Macro F1: 0.3322, Expected Return: 0.004771\n",
      "\n",
      "[77/88] Processing TOT...\n",
      "\n",
      "Processing TOT (Basic Matierials)...\n",
      "  Epoch 010 - train 0.68611 | val 1.36531\n",
      "  Epoch 019 - train 0.64266 | val 1.51901\n",
      "  Multiclass -> Micro Acc: 0.5829, Macro F1: 0.5732, Expected Return: -0.002024\n",
      "\n",
      "[78/88] Processing TSM...\n",
      "\n",
      "Processing TSM (Technology)...\n",
      "  Epoch 010 - train 0.78463 | val 0.73486\n",
      "  Epoch 020 - train 0.63379 | val 0.93275\n",
      "  Epoch 030 - train 0.54422 | val 0.82735\n",
      "  Multiclass -> Micro Acc: 0.4422, Macro F1: 0.3904, Expected Return: -0.002983\n",
      "\n",
      "[79/88] Processing UL...\n",
      "\n",
      "Processing UL (Consumer Goods)...\n",
      "  Epoch 010 - train 0.66881 | val 0.78815\n",
      "  Epoch 020 - train 0.60424 | val 0.82972\n",
      "  Epoch 030 - train 0.57340 | val 0.84664\n",
      "  Epoch 032 - train 0.55436 | val 0.98753\n",
      "  Multiclass -> Micro Acc: 0.4724, Macro F1: 0.2992, Expected Return: -0.003795\n",
      "\n",
      "[80/88] Processing UN...\n",
      "\n",
      "Processing UN (Consumer Goods)...\n",
      "  Epoch 010 - train 0.67117 | val 0.78215\n",
      "  Epoch 020 - train 0.61408 | val 1.06713\n",
      "  Multiclass -> Micro Acc: 0.4673, Macro F1: 0.3035, Expected Return: -0.001747\n",
      "\n",
      "[81/88] Processing UNH...\n",
      "\n",
      "Processing UNH (Healthcare)...\n",
      "  Epoch 010 - train 0.67706 | val 0.83379\n",
      "  Epoch 020 - train 0.64627 | val 0.98586\n",
      "  Epoch 021 - train 0.63691 | val 0.94279\n",
      "  Multiclass -> Micro Acc: 0.4422, Macro F1: 0.3347, Expected Return: -0.005588\n",
      "\n",
      "[82/88] Processing UPS...\n",
      "\n",
      "Processing UPS (Services)...\n",
      "  Epoch 010 - train 0.69346 | val 1.13755\n",
      "  Epoch 017 - train 0.62307 | val 1.48068\n",
      "  Multiclass -> Micro Acc: 0.4171, Macro F1: 0.2943, Expected Return: -0.012012\n",
      "\n",
      "[83/88] Processing UTX...\n",
      "\n",
      "Processing UTX (Industrial Goods)...\n",
      "  Epoch 010 - train 0.68356 | val 0.82878\n",
      "  Epoch 020 - train 0.61994 | val 0.99626\n",
      "  Epoch 024 - train 0.59010 | val 1.00770\n",
      "  Multiclass -> Micro Acc: 0.4975, Macro F1: 0.4651, Expected Return: -0.001828\n",
      "\n",
      "[84/88] Processing V...\n",
      "\n",
      "Processing V (Financial)...\n",
      "  Epoch 010 - train 0.80865 | val 1.09178\n",
      "  Epoch 018 - train 0.65837 | val 1.16552\n",
      "  Multiclass -> Micro Acc: 0.4322, Macro F1: 0.3018, Expected Return: -0.004765\n",
      "\n",
      "[85/88] Processing VZ...\n",
      "\n",
      "Processing VZ (Technology)...\n",
      "  Epoch 010 - train 0.67150 | val 0.91868\n",
      "  Epoch 020 - train 0.62655 | val 0.88591\n",
      "  Epoch 021 - train 0.62120 | val 0.94107\n",
      "  Multiclass -> Micro Acc: 0.5528, Macro F1: 0.5499, Expected Return: 0.001472\n",
      "\n",
      "[86/88] Processing WFC...\n",
      "\n",
      "Processing WFC (Financial)...\n",
      "  Epoch 010 - train 0.68068 | val 0.80613\n",
      "  Epoch 020 - train 0.63792 | val 1.03112\n",
      "  Multiclass -> Micro Acc: 0.4523, Macro F1: 0.4495, Expected Return: 0.001013\n",
      "\n",
      "[87/88] Processing WMT...\n",
      "\n",
      "Processing WMT (Services)...\n",
      "  Epoch 010 - train 0.77887 | val 2.33454\n",
      "  Epoch 017 - train 0.67242 | val 2.57385\n",
      "  Multiclass -> Micro Acc: 0.4774, Macro F1: 0.4763, Expected Return: -0.006365\n",
      "\n",
      "[88/88] Processing XOM...\n",
      "\n",
      "Processing XOM (Basic Matierials)...\n",
      "  Epoch 010 - train 0.69900 | val 0.81675\n",
      "  Epoch 020 - train 0.64333 | val 0.84565\n",
      "  Epoch 026 - train 0.61967 | val 0.87468\n",
      "  Multiclass -> Micro Acc: 0.5427, Macro F1: 0.5192, Expected Return: -0.000701\n",
      "\n",
      "================================================================================\n",
      "Pipeline completed: 88/88 companies processed successfully\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss curves saved to results/benchmarking/classification/LSTM_loss_curves.csv\n",
      "\n",
      "================================================================================\n",
      "STOCK PREDICTION PIPELINE RESULTS\n",
      "================================================================================\n",
      "Model: LSTM | Problem: multiclass\n",
      "Companies analyzed: 88\n",
      "Average samples per company: 1171\n",
      "\n",
      "==================================================\n",
      "OVERALL PERFORMANCE\n",
      "==================================================\n",
      "Micro Accuracy:         0.4758 (±0.0510)\n",
      "Macro F1 Score:         0.3718 (±0.0946)\n",
      "Expected Return:        -0.002453 (±0.0062)\n",
      "\n",
      "==================================================\n",
      "TOP 10 BY EXPECTED RETURN (mean)\n",
      "==================================================\n",
      "PICO                 | Conglomerates   | E[r]_mean: 1.1511e-02 | Macro-F1: 0.441\n",
      "CHTR                 | Services        | E[r]_mean: 1.1122e-02 | Macro-F1: 0.304\n",
      "BUD                  | Consumer Goods  | E[r]_mean: 9.2532e-03 | Macro-F1: 0.358\n",
      "AMZN                 | Services        | E[r]_mean: 6.6149e-03 | Macro-F1: 0.358\n",
      "SLB                  | Basic Matierials | E[r]_mean: 6.4343e-03 | Macro-F1: 0.304\n",
      "GMRE                 | Conglomerates   | E[r]_mean: 5.3843e-03 | Macro-F1: 0.112\n",
      "CHL                  | Technology      | E[r]_mean: 5.1794e-03 | Macro-F1: 0.330\n",
      "BHP                  | Basic Matierials | E[r]_mean: 4.9556e-03 | Macro-F1: 0.331\n",
      "TM                   | Consumer Goods  | E[r]_mean: 4.7709e-03 | Macro-F1: 0.332\n",
      "PFE                  | Healthcare      | E[r]_mean: 4.4371e-03 | Macro-F1: 0.445\n",
      "Directional Accuracy:   0.4786 (±0.0439)\n",
      "Matthews Correlation:   0.0126 (±0.0603)\n",
      "F1 Score:              0.2502 (±0.2373)\n",
      "Precision:             0.3931 (±0.2741)\n",
      "Recall:                0.2533 (±0.3032)\n",
      "\n",
      "==================================================\n",
      "PERFORMANCE BY SECTOR\n",
      "==================================================\n",
      "Basic Matierials     | Acc: 0.509±0.052 | MCC: 0.057 | Companies: 10\n",
      "Conglomerates        | Acc: 0.490±0.051 | MCC: -0.011 | Companies: 8\n",
      "Financial            | Acc: 0.483±0.039 | MCC: 0.001 | Companies: 10\n",
      "Healthcare           | Acc: 0.482±0.042 | MCC: 0.004 | Companies: 10\n",
      "Technology           | Acc: 0.482±0.036 | MCC: 0.013 | Companies: 10\n",
      "Consumer Goods       | Acc: 0.477±0.037 | MCC: 0.015 | Companies: 10\n",
      "Utilities            | Acc: 0.465±0.031 | MCC: 0.013 | Companies: 10\n",
      "Services             | Acc: 0.463±0.050 | MCC: 0.023 | Companies: 10\n",
      "Industrial Goods     | Acc: 0.458±0.048 | MCC: -0.006 | Companies: 10\n",
      "\n",
      "==================================================\n",
      "TOP 10 PERFORMERS (by Directional Accuracy)\n",
      "==================================================\n",
      "SPLP                 | Conglomerates   | Acc: 0.583 | MCC: 0.137\n",
      "TOT                  | Basic Matierials | Acc: 0.583 | MCC: 0.204\n",
      "CVX                  | Basic Matierials | Acc: 0.563 | MCC: 0.123\n",
      "AMZN                 | Services        | Acc: 0.558 | MCC: 0.000\n",
      "BUD                  | Consumer Goods  | Acc: 0.558 | MCC: 0.000\n",
      "MDT                  | Healthcare      | Acc: 0.553 | MCC: 0.104\n",
      "VZ                   | Technology      | Acc: 0.553 | MCC: 0.117\n",
      "BBL                  | Basic Matierials | Acc: 0.548 | MCC: 0.068\n",
      "HSBC                 | Financial       | Acc: 0.543 | MCC: 0.069\n",
      "XOM                  | Basic Matierials | Acc: 0.543 | MCC: 0.087\n",
      "Results saved to results/benchmarking/multiclass/LSTM.csv\n",
      "\n",
      "Displaying first 5 rows of LSTM results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>sector</th>\n",
       "      <th>model_type</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>horizon_steps</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_accuracy</th>\n",
       "      <th>expected_return_mean</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>...</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>directional_accuracy</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>val_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>epochs_trained</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>confusion_matrix_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Consumer Goods</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363325</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>1196</td>\n",
       "      <td>798</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>29</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABB</td>\n",
       "      <td>Industrial Goods</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332215</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>-0.008162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>1196</td>\n",
       "      <td>798</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>17</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366929</td>\n",
       "      <td>0.427027</td>\n",
       "      <td>-0.004317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.427027</td>\n",
       "      <td>1115</td>\n",
       "      <td>744</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>25</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340238</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>1196</td>\n",
       "      <td>798</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>27</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGFS</td>\n",
       "      <td>Conglomerates</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159356</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>-0.033999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>639</td>\n",
       "      <td>427</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  company            sector model_type problem_type  horizon_steps  macro_f1  \\\n",
       "0    AAPL    Consumer Goods       LSTM   multiclass              1  0.363325   \n",
       "1     ABB  Industrial Goods       LSTM   multiclass              1  0.332215   \n",
       "2    ABBV        Healthcare       LSTM   multiclass              1  0.366929   \n",
       "3     AEP         Utilities       LSTM   multiclass              1  0.340238   \n",
       "4    AGFS     Conglomerates       LSTM   multiclass              1  0.159356   \n",
       "\n",
       "   micro_accuracy  expected_return_mean  mse  mae  ...  precision    recall  \\\n",
       "0        0.427136             -0.006850  NaN  NaN  ...   0.550000  0.094828   \n",
       "1        0.497487             -0.008162  NaN  NaN  ...   0.000000  0.000000   \n",
       "2        0.427027             -0.004317  NaN  NaN  ...   0.523810  0.102804   \n",
       "3        0.452261             -0.003750  NaN  NaN  ...   0.800000  0.035714   \n",
       "4        0.433962             -0.033999  NaN  NaN  ...   0.428571  0.160714   \n",
       "\n",
       "   directional_accuracy  n_samples  train_samples  val_samples  test_samples  \\\n",
       "0              0.427136       1196            798          199           199   \n",
       "1              0.497487       1196            798          199           199   \n",
       "2              0.427027       1115            744          186           185   \n",
       "3              0.452261       1196            798          199           199   \n",
       "4              0.443396        639            427          106           106   \n",
       "\n",
       "   epochs_trained                                   confusion_matrix  \\\n",
       "0              29  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...   \n",
       "1              17  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...   \n",
       "2              25  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...   \n",
       "3              27  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...   \n",
       "4              18  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0...   \n",
       "\n",
       "                         confusion_matrix_normalized  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n{'='*25}\\n  RUNNING PIPELINE FOR: LSTM\\n{'='*25}\\n\")\n",
    "\n",
    "pipeline_LSTM = StockPredictionPipeline(\n",
    "    df=master_df,\n",
    "    feature_columns=feature_columns,\n",
    "    model_type='LSTM',\n",
    "    sequence_length=sequence_length,\n",
    "    problem_type='multiclass',\n",
    "    horizon_steps=1\n",
    ")\n",
    "\n",
    "results_LSTM = pipeline_LSTM.run_pipeline()\n",
    "\n",
    "agg_cm, labels = aggregate_confusions(results_LSTM, pipeline_LSTM.problem_type)\n",
    "if agg_cm is not None:\n",
    "    plot_confusion(agg_cm, display_labels, title=f\"LSTM - Aggregated Confusion Matrix\")\n",
    "    agg_norm = agg_cm / agg_cm.sum(axis=1, keepdims=True).clip(min=1)\n",
    "    plot_confusion(agg_norm, display_labels, title=f\"LSTM - Normalized Confusion Matrix\")\n",
    "    \n",
    "loss_df = pipeline_LSTM.get_loss_curves_df()\n",
    "\n",
    "pipeline_LSTM.save_loss_curves('results/benchmarking/')\n",
    "\n",
    "if results_LSTM is not None and not results_LSTM.empty:\n",
    "    analysis_LSTM = pipeline_LSTM.analyze_results()\n",
    "    pipeline_LSTM.save_results(results_LSTM, output_dir='results/benchmarking/')\n",
    "\n",
    "    all_pipelines[\"LSTM\"] = pipeline_LSTM\n",
    "    all_results_dfs[\"LSTM\"] = results_LSTM\n",
    "    all_analyses[\"LSTM\"] = analysis_LSTM\n",
    "\n",
    "    print(\"\\nDisplaying first 5 rows of LSTM results:\")\n",
    "    display(results_LSTM.head())\n",
    "else:\n",
    "    print(f\"\\n[FAILED] Pipeline for LSTM did not produce any results.\")\n",
    "\n",
    "del pipeline_LSTM"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
